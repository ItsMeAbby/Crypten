{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJU+aeeasg+4Fw3kpxdUUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItsMeAbby/Crypten/blob/main/Crypten.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Presention by:\n",
        "\n",
        " * Muhammad Abdullah Hayat, fd0002018\n",
        " * Muhammad Khurram Meraj, fd 0002042\n",
        " * Nayel Hashmi, fd0002022\n",
        "\n",
        "---\n",
        "\n",
        "# Secure Multi-Party Computation and CrypTen\n",
        "\n",
        "---\n",
        "\n",
        "## Agenda\n",
        "\n",
        "1. **Introduction**\n",
        "2. **What is Secure Multi-Party Computation (MPC)?**\n",
        "3. **Overview of CrypTen**\n",
        "4. **MPC Techniques in CrypTen**\n",
        "5. **Project Overview: Secure Logistic Regression**\n",
        "6. **Data Preparation in MPC**\n",
        "7. **Model Training with CrypTen**\n",
        "8. **Secure Inference**\n",
        "9. **Conclusion**\n",
        "10. **References**\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "- The rise of data privacy concerns necessitates secure ways to perform computations on private data.\n",
        "- **Secure Multi-Party Computation (MPC)** allows multiple parties to jointly compute a function over their inputs while keeping those inputs private.\n",
        "- **CrypTen** is a framework built on PyTorch that enables easy implementation of MPC techniques for machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "## What is Secure Multi-Party Computation (MPC)?\n",
        "\n",
        "- **Definition**: MPC allows parties to compute a function over their inputs without revealing the inputs themselves.\n",
        "- **Goal**: Ensure that no more information is revealed than what can be inferred from the output.\n",
        "- **Applications**:\n",
        "  - Privacy-preserving data analytics.\n",
        "  - Secure training of machine learning models.\n",
        "  - Collaborative computations among untrusted parties.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts in MPC\n",
        "\n",
        "- **Secret Sharing**:\n",
        "  - Data is split into shares distributed among parties.\n",
        "  - No single party holds enough information to reconstruct the original data.\n",
        "- **Computation on Shares**:\n",
        "  - Parties perform operations on their shares.\n",
        "  - Results are combined to obtain the final output without revealing individual inputs.\n",
        "\n",
        "---\n",
        "\n",
        "## Overview of CrypTen\n",
        "\n",
        "- **CrypTen** is a research framework for secure, privacy-preserving machine learning.\n",
        "- **Built on PyTorch**: Leverages PyTorch's APIs and functionalities.\n",
        "- **Features**:\n",
        "  - Easy-to-use API similar to PyTorch.\n",
        "  - Support for common neural network modules.\n",
        "  - Secure computation protocols implemented under the hood.\n",
        "\n",
        "---\n",
        "\n",
        "## Advantages of CrypTen\n",
        "\n",
        "- **Machine Learning First**: Designed with ML practitioners in mind.\n",
        "- **Eager Execution**: Immediate computation results, similar to PyTorch.\n",
        "- **Interoperability**: Compatibility with existing PyTorch models and datasets.\n",
        "- **Flexible and Extensible**: Supports custom models and functions.\n",
        "\n",
        "---\n",
        "\n",
        "## MPC Techniques in CrypTen\n",
        "\n",
        "- **Arithmetic Secret Sharing**:\n",
        "  - Data is represented as shares such that the sum of shares reconstructs the original value.\n",
        "  - Used for operations like addition and multiplication.\n",
        "- **Beaver Triples**:\n",
        "  - Pre-shared random values that facilitate secure multiplication.\n",
        "  - Allow parties to compute products without revealing operands.\n",
        "- **Secure Non-Linear Computations**:\n",
        "  - Approximations for functions like sigmoid, softmax, and logarithms.\n",
        "  - Use iterative methods suitable for MPC.\n",
        "\n",
        "---\n",
        "\n",
        "## Arithmetic Secret Sharing in CrypTen\n",
        "\n",
        "- **Additive Sharing**:\n",
        "  - Each party holds a share \\[x]i such that \\( x = ∑i[x]i \\).\n",
        "- **Operations**:\n",
        "  - **Addition**: Parties add their shares locally.\n",
        "  - **Multiplication**: Uses Beaver triples to securely compute products.\n",
        "\n",
        "---\n",
        "\n",
        "## Beaver Triples Explained\n",
        "\n",
        "- **Purpose**: Enable secure multiplication of secret-shared values.\n",
        "- **Process**:\n",
        "  1. Parties have \\( [a] \\), \\( [b] \\), \\( [c] \\) where \\( c = a × b \\).\n",
        "  2. Compute \\( [e] = [x] - [a] \\) and \\( [f] = [y] - [b] \\).\n",
        "  3. Reconstruct \\( e \\) and \\( f \\) securely.\n",
        "  4. Compute \\( [z] = [c] + e[b] + f[a] + ef \\).\n",
        "\n",
        "---\n",
        "\n",
        "## CrypTen's Approach to Non-Linear Functions\n",
        "\n",
        "- Uses secure approximations for functions that are not natively supported in MPC.\n",
        "\n",
        "- **Examples**:\n",
        "  - **Sigmoid**: Computed using the secure exponential function and division.\n",
        "  - **Logarithm**: Approximated using iterative methods like Newton-Raphson.\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview: Secure Logistic Regression\n",
        "\n",
        "- **Objective**: Train a logistic regression model over data held privately by multiple parties.\n",
        "- **Dataset**: Image data (similar to Fashion-MNIST) distributed among 3 parties.\n",
        "- **Tasks**:\n",
        "  - Prepare and encrypt data from each party.\n",
        "  - Combine data securely without revealing individual data.\n",
        "  - Train the model using CrypTen's secure computation protocols.\n",
        "  - Evaluate the model on a test set.\n",
        "\n",
        "---\n",
        "\n",
        "## Data Preparation in MPC\n",
        "\n",
        "- **Data Distribution**:\n",
        "  - Each party holds its own private dataset.\n",
        "  - Data is not shared in plaintext with other parties.\n",
        "- **Processing Steps**:\n",
        "  1. Each party normalizes its data locally.\n",
        "  2. Data is encrypted using secret sharing.\n",
        "  3. Encrypted data is saved and ready for computation.\n",
        "\n",
        "---\n",
        "\n",
        "## Secure Data Loading with CrypTen\n",
        "\n",
        "- **Encrypting Data**:\n",
        "  - Use `crypten.save_from_party()` to save encrypted data.\n",
        "  - Specify the source party to ensure data origins are known.\n",
        "- **Combining Data**:\n",
        "  - Parties collaboratively load encrypted data from others using `crypten.load_from_party()`.\n",
        "  - Data is combined securely, maintaining privacy.\n",
        "\n",
        "---\n",
        "\n",
        "## Model Training with CrypTen\n",
        "\n",
        "- **Model Definition**:\n",
        "  - Logistic Regression model defined using `crypten.nn.Module`.\n",
        "  - Consists of a single linear layer suitable for multi-class classification.\n",
        "- **Training Process**:\n",
        "  - Loss computed using `crypten.nn.CrossEntropyLoss()`.\n",
        "  - Gradients computed securely; parameters updated with `model.update_parameters()`.\n",
        "- **MPC in Training**:\n",
        "  - All computations are performed on encrypted data and model parameters.\n",
        "  - Uses arithmetic secret sharing and Beaver triples.\n",
        "\n",
        "---\n",
        "\n",
        "## Secure Inference\n",
        "\n",
        "- **Testing the Model**:\n",
        "  - Decrypted model can be used for standard inference.\n",
        "  - For secure inference, encrypt both the model and the test data.\n",
        "- **Process**:\n",
        "  1. Encrypt the trained model.\n",
        "  2. Encrypt the test data.\n",
        "  3. Perform inference using CrypTen's secure computation.\n",
        "  4. Decrypt the predictions for evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## Results and Evaluation\n",
        "\n",
        "- **Accuracy**:\n",
        "  - Model evaluated on the test set.\n",
        "  - Comparable performance to non-MPC training.\n",
        "- **Privacy Preservation**:\n",
        "  - Data from each party remains private throughout the process.\n",
        "  - No sensitive information is leaked during training or inference.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "- **CrypTen** enables secure machine learning using MPC techniques without requiring deep cryptographic expertise.\n",
        "- **Practical Implementation**:\n",
        "  - Similar API to PyTorch makes adoption easier.\n",
        "  - Secure computations are abstracted away, allowing focus on model development.\n",
        "- **Future Work**:\n",
        "  - Extend to more complex models and datasets.\n",
        "  - Explore performance optimizations and scalability.\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "1. **CrypTen: Secure Multi-Party Computation Meets Machine Learning**\n",
        "   - Knott et al., NeurIPS 2021.\n",
        "   - [Paper Link](https://proceedings.neurips.cc/paper/2021/file/2754518221cfbc8d25c13a06a4cb8421-Paper.pdf)\n",
        "2. **CrypTen GitHub Repository**\n",
        "   - [https://github.com/facebookresearch/crypten](https://github.com/facebookresearch/crypten)\n",
        "3. **Secure Multi-Party Computation (MPC)**\n",
        "   - Yao, A. C. (1986). How to generate and exchange secrets.\n",
        "   - [Link](https://dl.acm.org/doi/10.1145/138927.138930)\n",
        "4. **Beaver Multiplication Protocol**\n",
        "   - Beaver, D. (1991). Efficient Multiparty Protocols Using Circuit Randomization.\n",
        "   - [Link](https://link.springer.com/chapter/10.1007/0-387-34805-0_21)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uNer4Wf6-kSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secure Multi-Party Logistic Regression using CrypTen"
      ],
      "metadata": {
        "id": "xSm2cA9D31k-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll demonstrate how to perform logistic regression in a secure multi-party computation (MPC) setting using the **CrypTen** framework. We'll walk through the steps of preparing data held by multiple parties, training a logistic regression model without revealing the parties' private data, and evaluating the model's performance."
      ],
      "metadata": {
        "id": "7srp0zrq4AVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also explain the underlying MPC techniques used by CrypTen to perform secure computations, referencing the paper:\n",
        "\n",
        "> **CrypTen: Secure Multi-Party Computation Meets Machine Learning**  \n",
        "> Knott et al., NeurIPS 2021  \n",
        "> [Link to Paper](https://proceedings.neurips.cc/paper/2021/file/2754518221cfbc8d25c13a06a4cb8421-Paper.pdf)\n"
      ],
      "metadata": {
        "id": "E0Pc3Lnm4DST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First, let's set up the environment and import the necessary libraries.\n"
      ],
      "metadata": {
        "id": "j3caQq-p4MYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing and Importing Libraries"
      ],
      "metadata": {
        "id": "XwAQNbzD4RY2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "F2vMS5_Sai7I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os\n",
        "os.environ[\"SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL\"] = \"True\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q crypten"
      ],
      "metadata": {
        "id": "JXD4tWSga0nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import the `crypten` library and initialize it using `crypten.init()`. This sets up the communication backends and prepares CrypTen for secure multi-party computations."
      ],
      "metadata": {
        "id": "ZUgvrOIy4ZoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import crypten\n",
        "crypten.init()"
      ],
      "metadata": {
        "id": "2tHC0-Erav0y"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from crypten import mpc"
      ],
      "metadata": {
        "id": "w6ANIKDJazih"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We set the number of threads for PyTorch to 1 to avoid issues with multi-threading in a multi-process environment, which is common in MPC setups."
      ],
      "metadata": {
        "id": "RqsA0C2G4jc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_num_threads(1)\n"
      ],
      "metadata": {
        "id": "5BTkjt3Ch6ng"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "exzTZpyZ4pQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and Extracting the Dataset"
      ],
      "metadata": {
        "id": "wcvRLeSr4q-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll download a dataset to use in our example. The dataset contains images similar to Fashion-MNIST."
      ],
      "metadata": {
        "id": "KJtkeyV04xAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: !download http://www.gepperth.net/alexander/downloads/data1.zip as wget\n",
        "\n",
        "!wget http://www.gepperth.net/alexander/downloads/data1.zip\n",
        "!unzip data1.zip"
      ],
      "metadata": {
        "id": "u4SIPPxaZ4Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download and unzip the dataset, which will create a `fashion_mnist` directory containing image files."
      ],
      "metadata": {
        "id": "e2VvC5TP412z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parties=3"
      ],
      "metadata": {
        "id": "nKQVB1K_eW9s"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the number of parties participating in our MPC protocol to 3. Each party will have its own private dataset."
      ],
      "metadata": {
        "id": "gbdb-7Au44b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rf8GqJDd4t55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partitioning the Data Among Parties"
      ],
      "metadata": {
        "id": "gwjm1jre46mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll simulate the scenario where each party holds a portion of the dataset privately.\n"
      ],
      "metadata": {
        "id": "_l8fUZXP5CBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create len(parties) folder naming 0, 1, 2 and from fashion_mnist folder, put 1000 images from randomly starting from 0 to 5 filename,\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination directories\n",
        "source_dir = \"fashion_mnist\"  # Assuming fashion_mnist directory exists\n",
        "files = os.listdir(source_dir)\n",
        "\n",
        "# Create the destination directories if they don't exist\n",
        "for i in range(parties):\n",
        "    destination_dir = str(i)\n",
        "    if os.path.exists(destination_dir):\n",
        "        try:\n",
        "            shutil.rmtree(destination_dir)\n",
        "            print(f\"Folder '{destination_dir}' deleted successfully.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error deleting folder '{destination_dir}': {e}\")\n",
        "    else:\n",
        "        print(f\"Folder '{destination_dir}' not found.\")\n",
        "\n",
        "    os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "    # Randomly select 20 images from labels 0 to 4 for each party\n",
        "    for x in range(5):\n",
        "      random_files = random.sample([f for f in files if f.startswith(str(x))], 20)\n",
        "      for file in random_files:\n",
        "          source_path = os.path.join(source_dir, file)\n",
        "          destination_path = os.path.join(destination_dir, file)\n",
        "          shutil.copy(source_path, destination_path)\n",
        "\n",
        "# Create Test Set\n",
        "destination_dir=\"test\"\n",
        "if os.path.exists(destination_dir):\n",
        "        try:\n",
        "            shutil.rmtree(destination_dir)\n",
        "            print(f\"Folder '{destination_dir}' deleted successfully.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error deleting folder '{destination_dir}': {e}\")\n",
        "else:\n",
        "        print(f\"Folder '{destination_dir}' not found.\")\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "for x in range(5):\n",
        "      random_files = random.sample([f for f in files if f.startswith(str(x))], 5)\n",
        "      for file in random_files:\n",
        "          source_path = os.path.join(source_dir, file)\n",
        "          destination_path = os.path.join(destination_dir, file)\n",
        "          shutil.copy(source_path, destination_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N--V4WJ54-S4",
        "outputId": "e086aec1-b302-4bc5-cabc-06549a2f9644"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '0' deleted successfully.\n",
            "Folder '1' deleted successfully.\n",
            "Folder '2' deleted successfully.\n",
            "Folder 'test' deleted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For each party (0, 1, 2), we create a directory and copy 20 random images of each label from 0 to 4 into it.\n",
        "- We also create a separate `test` directory for evaluating our model later.\n"
      ],
      "metadata": {
        "id": "RchheoyF5VAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Images to NumPy Arrays and Saving as `.npz` Files"
      ],
      "metadata": {
        "id": "MsZGPFkJ5Xoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function to process the images and save them in a format suitable for training."
      ],
      "metadata": {
        "id": "AINyIFd35aJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from PIL import Image\n",
        "\n",
        "def make_npz(image_folder,h,w,c,output_file):\n",
        "\n",
        "\n",
        "    X = []\n",
        "    T = []\n",
        "\n",
        "    # Load images and labels\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith('.png'):\n",
        "            # Extract label from filename (assumes format: label-index.png)\n",
        "            label = int(filename.split('-')[0])\n",
        "            img_path = os.path.join(image_folder, filename)\n",
        "            img = Image.open(img_path)\n",
        "\n",
        "            # Resize image to the specified dimensions\n",
        "            img = img.resize((w, h))\n",
        "\n",
        "            # Convert image to grayscale if channels = 1\n",
        "            if c == 1:\n",
        "                img = img.convert('L')\n",
        "\n",
        "            # Convert image to NumPy array\n",
        "            img_array = np.array(img)\n",
        "\n",
        "            # Add channel dimension if needed\n",
        "            if c == 1:\n",
        "                img_array = img_array[:, :, np.newaxis]\n",
        "\n",
        "            X.append(img_array)\n",
        "            T.append(label)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    X = np.array(X)\n",
        "    T = np.array(T)\n",
        "\n",
        "    # Save the arrays to an .npz file\n",
        "    np.savez(output_file, X=X, T=T)\n",
        "    print(f'Data saved to {output_file}')\n"
      ],
      "metadata": {
        "id": "FPzOnIM0hMBD"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This function reads images from a folder, processes them, and saves the dataset as `.npz` files.\n",
        "- Parameters:\n",
        "  - `h`, `w`: Height and width to resize images.\n",
        "  - `c`: Number of channels (1 for grayscale).\n",
        "  - `output_file`: Name of the output `.npz` file."
      ],
      "metadata": {
        "id": "AK4lM2aT5eMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing and Saving Data for Each Party and the Test Set"
      ],
      "metadata": {
        "id": "qo2yqWXz5hem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(parties):\n",
        "    make_npz(str(i),28,28,1,f\"{i}.npz\")\n",
        "make_npz(\"test\",28,28,1,\"test.npz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxZcLY_ihfZM",
        "outputId": "fa4c8340-ef2b-4237-ece4-c2c2f2c14c2b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to 0.npz\n",
            "Data saved to 1.npz\n",
            "Data saved to 2.npz\n",
            "Data saved to test.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We create `.npz` files for each party and the test set with images resized to 28x28 pixels and converted to grayscale."
      ],
      "metadata": {
        "id": "R95bWkgr5jt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secure Data Loading and Sharing Using CrypTen"
      ],
      "metadata": {
        "id": "0_ubCqSV5mu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing and Saving Each Party's Data Securely\n",
        "\n",
        "We use CrypTen's MPC functionalities to securely process and save the data."
      ],
      "metadata": {
        "id": "zpCoCx7F5ohQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@mpc.run_multiprocess(world_size=3)\n",
        "def process_npz(npz_file, rank):\n",
        "    images, labels = [], []\n",
        "    data = np.load(npz_file)\n",
        "    X = data['X']  # Shape: (num_samples, height, width, channels)\n",
        "    T = data['T']  # Shape: (num_samples,)\n",
        "\n",
        "    # Normalize the data to [0, 1]\n",
        "    X = X / 255.0\n",
        "    X_tensor = torch.from_numpy(X).float()\n",
        "    T_tensor = torch.from_numpy(T).long()\n",
        "    # enc_X_tensor = crypten.cryptensor(X_tensor)\n",
        "    # enc_T_tensor = crypten.cryptensor(T_tensor)\n",
        "    crypten.save_from_party(X_tensor, f\"{rank}_images.pth\", src=rank)\n",
        "    crypten.save_from_party(T_tensor, f\"{rank}_labels.pth\", src=rank)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QSh_M9Sp3d2D"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `@mpc.run_multiprocess(world_size=3)`: This decorator runs the function in separate processes for each party.\n",
        "- Each party loads its own `.npz` file and normalizes the data.\n",
        "- `crypten.save_from_party` securely saves the data from each party, specifying the source party with `src=rank`.\n"
      ],
      "metadata": {
        "id": "PzlySyZa5uOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the Data Processing Function for Each Party"
      ],
      "metadata": {
        "id": "Bm-YHh_35yWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for each party process npz\n",
        "for idx,npz_file in enumerate([f\"{i}.npz\" for i in range(parties)]):\n",
        "    process_npz(npz_file, rank=idx)\n",
        "\n"
      ],
      "metadata": {
        "id": "XAeWZTE7B5vC"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We call the `process_npz` function for each party, passing the corresponding `.npz` file and rank."
      ],
      "metadata": {
        "id": "LBQ2CGq350-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@mpc.run_multiprocess(world_size=3)\n",
        "def combine_data():\n",
        "  # combine data\n",
        "  X_list = []\n",
        "  T_list = []\n",
        "  for rank in range(parties):\n",
        "    X_list.append(crypten.load_from_party(f\"{rank}_images.pth\", src=rank))\n",
        "    T_list.append(crypten.load_from_party(f\"{rank}_labels.pth\", src=rank))\n",
        "  X = torch.cat(X_list, dim=0)\n",
        "  T = torch.cat(T_list, dim=0)\n",
        "  return X,T"
      ],
      "metadata": {
        "id": "HHupuF8p543d"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We load and combine data from all parties securely.\n",
        "- `crypten.load_from_party` loads data saved by each party."
      ],
      "metadata": {
        "id": "mS3Xqw6m57Lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Securely Storing and Combining Data for Training"
      ],
      "metadata": {
        "id": "mZO6Fiba5949"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@mpc.run_multiprocess(world_size=3)\n",
        "def store_npz():\n",
        "    npz_files = [f\"{i}.npz\" for i in range(parties)]\n",
        "    rank = crypten.communicator.get().get_rank()\n",
        "\n",
        "    # List all npz files in the directory\n",
        "\n",
        "\n",
        "    # Each party processes its own npz file based on rank\n",
        "    npz_file = npz_files[rank]\n",
        "    data = np.load(npz_file)\n",
        "    X = data['X']  # Shape: (num_samples, height, width, channels)\n",
        "    T = data['T']  # Shape: (num_samples,)\n",
        "\n",
        "\n",
        "    # Normalize the data to [0, 1]\n",
        "    X = X / 255.0\n",
        "    X_tensor = torch.from_numpy(X).float()\n",
        "    T_tensor = torch.from_numpy(T).long()\n",
        "    crypten.print(f\"Rank {rank} has loaded data.\",X_tensor.shape,T_tensor.shape,in_order=True)\n",
        "\n",
        "    # Save the tensors from each party\n",
        "    for i in range(len(npz_files)):\n",
        "        crypten.save_from_party(X_tensor, f\"{i}_images.pth\", src=i)\n",
        "        crypten.save_from_party(T_tensor, f\"{i}_labels.pth\", src=i)\n",
        "\n",
        "store_npz()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4R0F5Tl0E3M",
        "outputId": "a4f334e5-1bf1-4f22-d360-9289207a7d43"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 0 has loaded data. torch.Size([100, 28, 28, 1]) torch.Size([100])\n",
            "Rank 1 has loaded data. torch.Size([100, 28, 28, 1]) torch.Size([100])\n",
            "Rank 2 has loaded data. torch.Size([100, 28, 28, 1]) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining Data from All Parties"
      ],
      "metadata": {
        "id": "QX0-1N_X52lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We combine the data from all parties and perform one-hot encoding of labels.\n",
        "- The combined data and encrypted labels are saved for training."
      ],
      "metadata": {
        "id": "dYOBkRwY6EMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@mpc.run_multiprocess(world_size=5,maxsize=5)\n",
        "def combine_data():\n",
        "    npz_files = [f\"{i}.npz\" for i in range(parties)]\n",
        "    # print(f\"World size: {world_size}\")\n",
        "    # Combine data from all parties\n",
        "    X_list = []\n",
        "    T_list = []\n",
        "    for i in range(len(npz_files)):\n",
        "        # Each party loads data from all parties\n",
        "        X_i = crypten.load_from_party(f\"{i}_images.pth\", src=i)\n",
        "        T_i = crypten.load_from_party(f\"{i}_labels.pth\", src=i)\n",
        "        # crypten.print(f\"Rank {i} has loaded data. {X_i.shape}, {T_i.shape}, {T_i.get_plain_text()} \")\n",
        "        X_list.append(X_i)\n",
        "        T_list.append(T_i)\n",
        "\n",
        "\n",
        "    # Concatenate the data\n",
        "    X_combined = torch.cat(X_list, dim=0)\n",
        "    T_combined = torch.cat(T_list, dim=0)\n",
        "    dec=T_combined.get_plain_text()\n",
        "    input_dim = X_combined.shape[1:]\n",
        "    max_label=int(max(dec))\n",
        "    output_dim = max_label+1\n",
        "    # do one hot encoding\n",
        "    labels=[]\n",
        "    for label in dec:\n",
        "        # long_dtype convert label to long\n",
        "        x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
        "        labels.append(x)\n",
        "    labels = torch.stack(labels)\n",
        "    enc_labels=crypten.cryptensor(labels)\n",
        "\n",
        "    crypten.save(X_combined, \"X_combined.pth\")\n",
        "    crypten.save(enc_labels, \"T_combined.pth\")\n",
        "\n",
        "combine_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAe1F2450Unm",
        "outputId": "fe49fd4d-3b00-4b6f-c829-e84bf6c024a8"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = load_closure(f, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = load_closure(f, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = load_closure(f, **kwargs)\n",
            "<ipython-input-102-2993e36afe96>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-102-2993e36afe96>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-102-2993e36afe96>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-102-2993e36afe96>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-102-2993e36afe96>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Logistic Regression Model\n",
        "\n",
        "We define a logistic regression model suitable for multi-class classification."
      ],
      "metadata": {
        "id": "xEDwJJ2l6Vog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The model inherits from `crypten.nn.Module`, allowing it to be used within CrypTen's MPC framework.\n",
        "- It consists of a single linear layer that maps the flattened input to the output classes."
      ],
      "metadata": {
        "id": "XhdiTxuH6zZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import crypten\n",
        "import torch\n",
        "\n",
        "from crypten import mpc\n",
        "\n",
        "    # crypten.init()\n",
        "# Remove the initial `crypten.init()`\n",
        "crypten.init()  # No need to call this here\n",
        "\n",
        "class LogisticRegression(crypten.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "      super().__init__()\n",
        "      height, width,channels = input_dim\n",
        "      self.linear = crypten.nn.Linear(channels * height * width, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "      batch_size = x.size(0)\n",
        "      x = x.reshape(batch_size, -1)\n",
        "      return self.linear(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mezT-i4s7Y8",
        "outputId": "16f51611-96b7-4822-f59d-3767492e8305"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:64: RuntimeWarning: CrypTen is already initialized.\n",
            "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CrypTen's Approach to MPC in Neural Networks"
      ],
      "metadata": {
        "id": "v-bECzOa66Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Secret Sharing of Parameters**: Model parameters are secret-shared among the parties. Each party holds a share of the parameters, and computations are performed on these shares.\n",
        "- **Secure Computations**: Linear operations are computed using arithmetic secret sharing, where each party performs computations on their shares, and the results remain secret-shared."
      ],
      "metadata": {
        "id": "uEwTVFEk69t0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model Securely"
      ],
      "metadata": {
        "id": "NErNpOUd7Ecf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Defining the Training Function"
      ],
      "metadata": {
        "id": "U_tc1FaV7F3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train_data(model, X, y, epochs=5, learning_rate=0.05, batch_size=128):\n",
        "    criterion = crypten.nn.CrossEntropyLoss()\n",
        "    num_samples = X.size(0)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.zero_grad()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        # Shuffle the data\n",
        "        indices = torch.randperm(num_samples)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "        # Iterate over batches\n",
        "        for start_idx in range(0, num_samples, batch_size):\n",
        "            end_idx = min(start_idx + batch_size, num_samples)\n",
        "            X_batch = X[start_idx:end_idx]\n",
        "            y_batch = y[start_idx:end_idx]\n",
        "\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            epoch_loss += int(loss.get_plain_text())\n",
        "\n",
        "            loss.backward()\n",
        "            model.update_parameters(learning_rate)\n",
        "            batch_number=int(start_idx/batch_size)\n",
        "            crypten.print(f\"epoch: {epoch} batch: {batch_number} loss:{loss.get_plain_text()}\")\n",
        "\n",
        "        # crypten.print(f\"epoch {epoch} loss: {epoch_loss / (num_samples // batch_size)}\")\n",
        "\n",
        "    return model\n",
        ""
      ],
      "metadata": {
        "id": "vU5uyAQvGN3I"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The training function resembles standard PyTorch training loops but uses CrypTen functionalities.\n",
        "- **Cross-Entropy Loss**: We use `crypten.nn.CrossEntropyLoss()`, which computes the loss securely using MPC techniques.\n",
        "- **Backward Pass**: Gradients are computed securely, and parameters are updated using `model.update_parameters()`."
      ],
      "metadata": {
        "id": "WegBVHCs7UEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "@mpc.run_multiprocess(world_size=5)\n",
        "def train_test():\n",
        "    npz_files = [f\"{i}.npz\" for i in range(parties)]\n",
        "    # Combine data from all parties\n",
        "    X_list = []\n",
        "    T_list = []\n",
        "    for i in range(len(npz_files)):\n",
        "        # Each party loads data from all parties\n",
        "        X_i = crypten.load_from_party(f\"{i}_images.pth\", src=i)\n",
        "        T_i = crypten.load_from_party(f\"{i}_labels.pth\", src=i)\n",
        "        # print(f\"Rank {i} has loaded data. {X_i.shape}, {T_i.shape}, {T_i.get_plain_text()} \")\n",
        "        X_list.append(X_i)\n",
        "        T_list.append(T_i)\n",
        "\n",
        "\n",
        "    # Concatenate the data\n",
        "    X_combined = torch.cat(X_list, dim=0)\n",
        "    T_combined = torch.cat(T_list, dim=0)\n",
        "    dec=T_combined.get_plain_text()\n",
        "    input_dim = X_combined.shape[1:]\n",
        "    max_label=int(max(dec))\n",
        "    output_dim = max_label+1\n",
        "    # do one hot encoding\n",
        "    labels=[]\n",
        "    for label in dec:\n",
        "        # long_dtype convert label to long\n",
        "        x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
        "        labels.append(x)\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    # print(f\"Input dimension: {input_dim}, Output dimension: {output_dim} {T_combined.get_plain_text()}\")\n",
        "    model=LogisticRegression(input_dim,output_dim)\n",
        "    model_enc=model.encrypt(src=4)\n",
        "    enc_labels=crypten.cryptensor(labels)\n",
        "    model=train_data(model_enc,X_combined,enc_labels)\n",
        "    # save model\n",
        "    torch.save(model.decrypt(),\"model.pth\")\n",
        "\n",
        "\n",
        "train_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U6aF59P7hvQ",
        "outputId": "775741bd-8475-4182-d5ac-6c680714fd4d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = load_closure(f, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = load_closure(f, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = load_closure(f, **kwargs)\n",
            "<ipython-input-105-44b8695418da>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-105-44b8695418da>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-105-44b8695418da>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-105-44b8695418da>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n",
            "<ipython-input-105-44b8695418da>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x=torch.nn.functional.one_hot(torch.tensor(label,dtype=torch.long),output_dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 batch: 0 loss:1.657684326171875\n",
            "epoch: 0 batch: 1 loss:1.5697479248046875\n",
            "epoch: 0 batch: 2 loss:1.481292724609375\n",
            "epoch: 1 batch: 0 loss:1.3783721923828125\n",
            "epoch: 1 batch: 1 loss:1.3565826416015625\n",
            "epoch: 1 batch: 2 loss:1.28399658203125\n",
            "epoch: 2 batch: 0 loss:1.2330780029296875\n",
            "epoch: 2 batch: 1 loss:1.1878509521484375\n",
            "epoch: 2 batch: 2 loss:1.115020751953125\n",
            "epoch: 3 batch: 0 loss:1.1845245361328125\n",
            "epoch: 3 batch: 1 loss:1.078125\n",
            "epoch: 3 batch: 2 loss:1.0481719970703125\n",
            "epoch: 4 batch: 0 loss:1.092193603515625\n",
            "epoch: 4 batch: 1 loss:1.0303192138671875\n",
            "epoch: 4 batch: 2 loss:0.935302734375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How CrypTen Performs MPC During Training\n",
        "\n",
        "- **Arithmetic Secret Sharing**: The model parameters and data are secret-shared using arithmetic secret sharing, enabling secure linear operations.\n",
        "- **Beaver Triples**: For secure multiplication during backpropagation, CrypTen uses Beaver triples to compute products without revealing the operands.\n",
        "- **Communication**: Parties communicate as needed for secure computations, but the actual data remains private."
      ],
      "metadata": {
        "id": "anV9TJa07YL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "hm-NfU587oId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluate the trained model on the test set.\n",
        "\n",
        "### Loading and Testing the Model"
      ],
      "metadata": {
        "id": "6LiqsFyD7qHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load decryted model\n",
        "\n",
        "model=crypten.load(\"model.pth\")\n",
        "# torch.mode.eval()\n",
        "data=np.load(\"test.npz\")\n",
        "crypten.init()\n",
        "correct=[]\n",
        "for i in range(len(os.listdir(\"test\"))):\n",
        "  image_0=data[\"X\"][i]\n",
        "  label_i=data[\"T\"][i]\n",
        "  image_t=torch.from_numpy(image_0).float()\n",
        "  prediction = model(image_t.unsqueeze(0))\n",
        "  crypten.print(f\"original label: {int(label_i)}, predicted label: {int(prediction[0].argmax())}\")\n",
        "  if int(prediction[0].argmax())==int(label_i):\n",
        "    correct.append(1)\n",
        "  else:\n",
        "    correct.append(0)\n",
        "crypten.print(f\"accuracy: {sum(correct)/len(correct)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_vIm7O-v4Yp",
        "outputId": "0f9bf7b0-10c3-4422-dc6a-83d56d4e49c5"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original label: 4, predicted label: 4\n",
            "original label: 2, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 0, predicted label: 4\n",
            "original label: 2, predicted label: 4\n",
            "original label: 2, predicted label: 4\n",
            "original label: 4, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 0, predicted label: 0\n",
            "original label: 1, predicted label: 1\n",
            "original label: 0, predicted label: 0\n",
            "original label: 0, predicted label: 4\n",
            "original label: 1, predicted label: 1\n",
            "original label: 4, predicted label: 3\n",
            "original label: 3, predicted label: 3\n",
            "original label: 2, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 4, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 1, predicted label: 1\n",
            "original label: 1, predicted label: 1\n",
            "original label: 0, predicted label: 3\n",
            "original label: 1, predicted label: 1\n",
            "original label: 2, predicted label: 4\n",
            "original label: 4, predicted label: 4\n",
            "accuracy: 0.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/crypten/__init__.py:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  obj = load_closure(f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We load the decrypted model and the test data.\n",
        "- We iterate through the test samples, performing inference and comparing predictions with true labels.\n",
        "- **Note**: Since the model is decrypted, inference is standard."
      ],
      "metadata": {
        "id": "Jhjs7qVm7w55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Secure Inference with Encrypted Model and Data"
      ],
      "metadata": {
        "id": "TShkcEBk7z7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load decryted model\n",
        "\n",
        "model=torch.load(\"model.pth\")\n",
        "\n",
        "# torch.mode.eval()\n",
        "data=np.load(\"test.npz\")\n",
        "crypten.init()\n",
        "model.encrypt()\n",
        "correct=[]\n",
        "for i in range(len(os.listdir(\"test\"))):\n",
        "    image_0=data[\"X\"][i]\n",
        "    label_i=data[\"T\"][i]\n",
        "    image_t=torch.from_numpy(image_0).float()\n",
        "    enc_image=crypten.cryptensor(image_t.unsqueeze(0))\n",
        "    prediction = model(enc_image)\n",
        "    crypten.print(f\"original label: {int(label_i)}, predicted label: {int(prediction.get_plain_text()[0].argmax())}\")\n",
        "    if int(prediction.get_plain_text()[0].argmax())==int(label_i):\n",
        "      correct.append(1)\n",
        "    else:\n",
        "      correct.append(0)\n",
        "crypten.print(f\"accuracy: {sum(correct)/len(correct)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aYHZOvIwB66",
        "outputId": "e1c5f46b-c855-474a-85d1-ca734b4ac410"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-107-08bca3ada4a7>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model=torch.load(\"model.pth\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original label: 4, predicted label: 4\n",
            "original label: 2, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 0, predicted label: 4\n",
            "original label: 2, predicted label: 4\n",
            "original label: 2, predicted label: 4\n",
            "original label: 4, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 0, predicted label: 0\n",
            "original label: 1, predicted label: 1\n",
            "original label: 0, predicted label: 0\n",
            "original label: 0, predicted label: 4\n",
            "original label: 1, predicted label: 1\n",
            "original label: 4, predicted label: 3\n",
            "original label: 3, predicted label: 3\n",
            "original label: 2, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 4, predicted label: 4\n",
            "original label: 3, predicted label: 3\n",
            "original label: 1, predicted label: 1\n",
            "original label: 1, predicted label: 1\n",
            "original label: 0, predicted label: 3\n",
            "original label: 1, predicted label: 1\n",
            "original label: 2, predicted label: 4\n",
            "original label: 4, predicted label: 4\n",
            "accuracy: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We encrypt the model and perform inference using encrypted data.\n",
        "- The predictions are obtained securely, and only the necessary outputs are decrypted for evaluation.\n",
        "- This demonstrates CrypTen's capability to perform secure inference without revealing the input data or the model parameters."
      ],
      "metadata": {
        "id": "t2-53E8O726B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Underlying MPC Techniques in CrypTen"
      ],
      "metadata": {
        "id": "i_NB3dm476mF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CrypTen uses several MPC techniques to ensure computations are performed securely:\n",
        "\n",
        "### Arithmetic Secret Sharing\n",
        "\n",
        "- **Concept**: Each party holds a share of the data such that the sum of all shares reconstructs the original data.\n",
        "- **Operations**:\n",
        "  - **Addition**: Parties add their shares locally.\n",
        "  - **Multiplication**: Uses Beaver triples to perform multiplication without revealing the operands.\n"
      ],
      "metadata": {
        "id": "NYUqvO1n8GTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of parties\n",
        "num_parties = 3\n",
        "\n",
        "# Secret value to be shared\n",
        "secret_value = 42\n",
        "\n",
        "# Prime modulus for the finite field (to prevent overflow)\n",
        "prime_modulus = 67  # Choose a prime larger than the secret_value\n",
        "\n",
        "# Generate random shares for the first (n-1) parties\n",
        "import random\n",
        "\n",
        "shares = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "\n",
        "# Compute the final share such that the sum modulo prime_modulus equals the secret_value\n",
        "final_share = (secret_value - sum(shares)) % prime_modulus\n",
        "shares.append(final_share)\n",
        "\n",
        "# Distribute shares to parties\n",
        "for idx, share in enumerate(shares):\n",
        "    print(f\"Party {idx + 1} receives share: {share}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFyMLvURDS8T",
        "outputId": "85fa46d1-b041-41eb-a43a-16eeedbe0901"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Party 1 receives share: 22\n",
            "Party 2 receives share: 40\n",
            "Party 3 receives share: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "- We define a `secret_value` that we want to share among `num_parties`.\n",
        "- We choose a `prime_modulus` for the finite field to avoid overflow and ensure proper modular arithmetic.\n",
        "- We generate random shares for the first `n-1` parties.\n",
        "- The final share is computed to ensure the sum of all shares modulo `prime_modulus` equals the `secret_value`.\n",
        "- Each party receives one share."
      ],
      "metadata": {
        "id": "YkNYw5DCDp3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruction of the Secret"
      ],
      "metadata": {
        "id": "BjCCbpWYEL2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruction (each party provides their share)\n",
        "reconstructed_value = sum(shares) % prime_modulus\n",
        "print(f\"The reconstructed secret is: {reconstructed_value}\")"
      ],
      "metadata": {
        "id": "Yrw7oLCzELh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "- By summing all the shares and taking modulo `prime_modulus`, we retrieve the original `secret_value`.\n",
        "- This demonstrates that no single party knows the secret, but together they can reconstruct it.\n"
      ],
      "metadata": {
        "id": "cKUt-V0rEV_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addition of Secret-Shared Values"
      ],
      "metadata": {
        "id": "r6DDPgeTEYaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arithmetic secret sharing supports operations directly on the shares without needing to reconstruct the secret. For addition:\n",
        "\n",
        "Suppose we have two secret values, `a` and `b`."
      ],
      "metadata": {
        "id": "iojB8KRMEaaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Secret values\n",
        "a = 30\n",
        "b = 20\n",
        "print(f\"Secret a: {a}\") # Added print statement\n",
        "print(f\"Secret b: {b}\") # Added print statement\n",
        "\n",
        "# Prime modulus for the finite field (to prevent overflow)\n",
        "prime_modulus = 67  # Choose a prime larger than the secret_value\n",
        "print(f\"Prime modulus: {prime_modulus}\") # Added print statement\n",
        "\n",
        "# Number of parties\n",
        "num_parties = 3\n",
        "print(f\"Number of parties: {num_parties}\") # Added print statement\n",
        "\n",
        "\n",
        "# Generate random shares for the first (n-1) parties\n",
        "shares_a = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "\n",
        "shares_a.append((a - sum(shares_a)) % prime_modulus)\n",
        "print(f\"Shares of a (all parties): {shares_a}\") # Added print statement\n",
        "\n",
        "shares_b = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "shares_b.append((b - sum(shares_b)) % prime_modulus)\n",
        "print(f\"Shares of b (all parties): {shares_b}\") # Added print statement\n",
        "\n",
        "# Add shares locally\n",
        "shares_sum = [(s_a + s_b) % prime_modulus for s_a, s_b in zip(shares_a, shares_b)]\n",
        "print(f\"Shares of sum (a+b): {shares_sum}\") # Added print statement\n",
        "\n",
        "# Reconstruct the sum\n",
        "reconstructed_sum = sum(shares_sum) % prime_modulus\n",
        "print(f\"The sum of secrets a and b is: {reconstructed_sum}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVNtK7WWEfmM",
        "outputId": "bb54c64e-5389-4a11-86b8-4cb029af76cd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secret a: 30\n",
            "Secret b: 20\n",
            "Prime modulus: 67\n",
            "Number of parties: 3\n",
            "Shares of a (all parties): [62, 46, 56]\n",
            "Shares of b (all parties): [60, 48, 46]\n",
            "Shares of sum (a+b): [55, 27, 35]\n",
            "The sum of secrets a and b is: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "- Each party adds their shares of `a` and `b` locally.\n",
        "- The sum of the shares reconstructs the sum of the secrets.\n"
      ],
      "metadata": {
        "id": "j7SGDVkZFO8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Beaver Triples\n",
        "\n",
        "- **Purpose**: To enable secure multiplication of secret-shared values.\n",
        "- **Process**:\n",
        "  1. Parties obtain a pre-shared triple \\(a, b, c\\) where \\( c = a × b \\)\\.\n",
        "  2. They compute \\( e = x - a \\) and \\( f = y - b \\) securely.\n",
        "  3. The product \\( x × y \\) is reconstructed using \\( c + e × b + a × f + e × f \\).\n",
        "\n"
      ],
      "metadata": {
        "id": "rcx6VlVS9JRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Beaver Triples\n",
        "\n",
        "A Beaver triple consists of three values `(a, b, c)` such that `c = a * b`, and `a` and `b` are random values."
      ],
      "metadata": {
        "id": "wBe4Wp8EGA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random values for a and b\n",
        "a = random.randint(0, prime_modulus - 1)\n",
        "b = random.randint(0, prime_modulus - 1)\n",
        "c = (a * b) % prime_modulus\n",
        "\n",
        "# Secret-share a, b, c among the parties\n",
        "shares_a = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "shares_a.append((a - sum(shares_a)) % prime_modulus)\n",
        "\n",
        "print(f\"Shares of a (all parties): {shares_a}\") # Added print statement\n",
        "\n",
        "shares_b = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "shares_b.append((b - sum(shares_b)) % prime_modulus)\n",
        "\n",
        "print(f\"Shares of b (all parties): {shares_b}\") # Added print statement\n",
        "\n",
        "shares_c = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "shares_c.append((c - sum(shares_c)) % prime_modulus)\n",
        "\n",
        "print(f\"Shares of c (all parties): {shares_c}\") # Added print statement\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXALQ84KFakO",
        "outputId": "a1966d08-c9ef-4c18-e2a3-390c0fb797a9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shares of a (all parties): [31, 52, 34]\n",
            "Shares of b (all parties): [40, 18, 26]\n",
            "Shares of c (all parties): [15, 20, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Secure Multiplication Using Beaver Triples"
      ],
      "metadata": {
        "id": "g4uxwzLeGEO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose parties have secret-shared values `[x]` and `[y]` that they wish to multiply."
      ],
      "metadata": {
        "id": "Fa22hW_iGGdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Secret values to multiply\n",
        "x = 15\n",
        "y = 7\n",
        "\n",
        "# Secret-share x and y\n",
        "shares_x = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "shares_x.append((x - sum(shares_x)) % prime_modulus)\n",
        "\n",
        "print(f\"Shares of x (all parties): {shares_x}\")\n",
        "\n",
        "shares_y = [random.randint(0, prime_modulus - 1) for _ in range(num_parties - 1)]\n",
        "shares_y.append((y - sum(shares_y)) % prime_modulus)\n",
        "\n",
        "print(f\"Shares of y (all parties): {shares_y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anyI13wFGLWQ",
        "outputId": "3574efd7-3a00-4665-ded2-6195bf957b2f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shares of x (all parties): [35, 1, 46]\n",
            "Shares of y (all parties): [46, 65, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beaver Multiplication Protocol Steps**:"
      ],
      "metadata": {
        "id": "OdC5E7ZiGdfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Compute local shares of e and f**:\n",
        "\n",
        "    Each party computes:"
      ],
      "metadata": {
        "id": "S2UGv60BGg_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shares_e = [(s_x - s_a) % prime_modulus for s_x, s_a in zip(shares_x, shares_a)]\n",
        "shares_f = [(s_y - s_b) % prime_modulus for s_y, s_b in zip(shares_y, shares_b)]\n",
        "\n",
        "print(f\"Shares of e (all parties): {shares_e}\")\n",
        "print(f\"Shares of f (all parties): {shares_f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a94roc7GjiP",
        "outputId": "94b6d2e8-9652-4a79-e18c-414f34eea5c2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shares of e (all parties): [4, 16, 12]\n",
            "Shares of f (all parties): [6, 47, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Reveal e and f**:"
      ],
      "metadata": {
        "id": "VYEdZnbHGvBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parties collaboratively reconstruct `e` and `f`:\n",
        "\n",
        "e = sum(shares_e) % prime_modulus\n",
        "f = sum(shares_f) % prime_modulus\n",
        "\n",
        "print(f\"Reconstructed e: {e}\")\n",
        "print(f\"Reconstructed f: {f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS31u6rZG2gV",
        "outputId": "221f1b62-02af-4d3a-feef-57fbbc2bd1bc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed e: 32\n",
            "Reconstructed f: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shares_prod = [\n",
        "        (s_c + e * s_b + f * s_a + (e * f if i == 0 else 0)) % prime_modulus\n",
        "        for i, (s_c, s_a, s_b) in enumerate(zip(shares_c, shares_a, shares_b))\n",
        "    ]\n",
        "shares_prod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyIP08msHBO3",
        "outputId": "70ee06c3-43e9-403d-de54-2c2e168283bd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[62, 9, 34]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Only one party adds the term `e * f` to avoid duplication."
      ],
      "metadata": {
        "id": "QHcq7pVOHKf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Reconstruct the product**:"
      ],
      "metadata": {
        "id": "JWLUs9cyHJWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x * y) % prime_modulus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs4iCS2QL9OP",
        "outputId": "45d22688-c9e6-4de5-a7fa-4a9acbc9c26a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product = sum(shares_prod)\n",
        "print(f\"The product of x and y is: {product}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjZIEAjdHPct",
        "outputId": "58656702-a418-4198-ed09-78f2e9a85fa5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The product of x and y is: 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "- **Step 1**: Each party computes the difference between their shares and the Beaver triple shares.\n",
        "- **Step 2**: `e` and `f` are revealed, but since `a` and `b` are random, this doesn't leak information about `x` and `y`.\n",
        "- **Step 3**: Parties compute their shares of the product using the formula.\n",
        "- **Step 4**: Summing the shares reconstructs the product `x * y`.\n"
      ],
      "metadata": {
        "id": "48Orx_HcHAru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Compute local shares of the product**:"
      ],
      "metadata": {
        "id": "PqVMIcSDG-Vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Secure Non-Linear Functions\n",
        "\n",
        "- **Approximations**: Functions like sigmoid, softmax, and logarithms are approximated using polynomial or iterative methods suitable for secure computation.\n",
        "- **CrypTen Implementations**:\n",
        "  - Uses fixed-point arithmetic for real numbers.\n",
        "  - Employs methods like Newton-Raphson iterations for functions like reciprocal and square root.\n"
      ],
      "metadata": {
        "id": "cjwop6bw9MEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Communication and Synchronization\n",
        "\n",
        "- **CrypTen Backend**: Manages communication between parties, ensuring messages are exchanged securely.\n",
        "- **Synchronization**: Functions decorated with `@mpc.run_multiprocess` run synchronously across parties.\n"
      ],
      "metadata": {
        "id": "242FChV59PbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Data Privacy\n",
        "\n",
        "- **Encrypted Inputs**: Data from each party is encrypted (secret-shared) before any computation.\n",
        "- **Encrypted Outputs**: Intermediate computations remain encrypted; only the final results are decrypted if necessary.\n"
      ],
      "metadata": {
        "id": "oUrpGWh39Rti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Conclusion\n",
        "\n",
        "In this notebook, we demonstrated how to perform logistic regression in a secure multi-party computation setting using CrypTen. We walked through data preparation, model definition, training, and evaluation, all while preserving the privacy of each party's data.\n",
        "\n",
        "CrypTen leverages MPC techniques, such as arithmetic secret sharing and Beaver triples, to enable secure computations. By providing an API similar to PyTorch, CrypTen makes it accessible for machine learning practitioners to implement privacy-preserving models without deep knowledge of cryptography.\n",
        "\n"
      ],
      "metadata": {
        "id": "-FhGXJEI9VPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## References\n",
        "\n",
        "- **CrypTen: Secure Multi-Party Computation Meets Machine Learning**, Knott et al., NeurIPS 2021.\n",
        "  - [Paper Link](https://proceedings.neurips.cc/paper/2021/file/2754518221cfbc8d25c13a06a4cb8421-Paper.pdf)\n",
        "- **CrypTen GitHub Repository**: [https://github.com/facebookresearch/crypten](https://github.com/facebookresearch/crypten)"
      ],
      "metadata": {
        "id": "Sqf-UrzH9XGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all pth files from folder\n",
        "import os\n",
        "for file in os.listdir():\n",
        "    if file.endswith(\".pth\"):\n",
        "        os.remove(file)"
      ],
      "metadata": {
        "id": "nrs3AH_OHT94"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y2CKvM2YAq20"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}